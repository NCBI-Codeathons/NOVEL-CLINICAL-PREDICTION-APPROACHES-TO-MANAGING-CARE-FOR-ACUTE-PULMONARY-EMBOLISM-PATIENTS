{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import ExtraTreeClassifier, DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths to files\n",
    "data_path = '/project/hackathon/hackers09/shared/data/'\n",
    "cancer_path = os.path.join(data_path, 'df_cancer.csv')\n",
    "echo_path = os.path.join(data_path, 'df_echo.csv')\n",
    "encounter_path = os.path.join(data_path, 'df_encounter.csv')\n",
    "labs_path = os.path.join(data_path, 'df_labs.csv')\n",
    "outcome_path = os.path.join(data_path, 'df_outcome.csv')\n",
    "problist_path = os.path.join(data_path, 'df_problist.csv')\n",
    "radiology_path = os.path.join(data_path, 'df_radiology.csv')\n",
    "registry_path = os.path.join(data_path, 'df_registry.csv')\n",
    "vitals_path = os.path.join(data_path, 'df_vitals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in dataframes\n",
    "cancer_df = pd.read_csv(cancer_path, encoding='ISO-8859-1')\n",
    "cancer_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "echo_df = pd.read_csv(echo_path, encoding='ISO-8859-1')\n",
    "echo_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "encounter_df = pd.read_csv(encounter_path, encoding='ISO-8859-1')\n",
    "encounter_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "labs_df = pd.read_csv(labs_path, encoding='ISO-8859-1')\n",
    "labs_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "outcome_df = pd.read_csv(outcome_path, encoding='ISO-8859-1')\n",
    "outcome_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "problist_df = pd.read_csv(problist_path, encoding='ISO-8859-1')\n",
    "problist_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "radiology_df = pd.read_csv(radiology_path, encoding='ISO-8859-1')\n",
    "radiology_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "registry_df = pd.read_csv(registry_path, encoding='ISO-8859-1')\n",
    "registry_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "vitals_df = pd.read_csv(vitals_path, encoding='ISO-8859-1')\n",
    "vitals_df.set_index(\"HSP_ENC\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to merge cancer data\n",
    "def merge_cancer(enc_df, cnc_df):\n",
    "    #Make modifications to cancer df\n",
    "    mod_cancer_df = cnc_df.copy()\n",
    "    mod_cancer_df.reset_index(level=0, inplace=True)\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown, Missing Remission Date', 'cancer_at_enc'] = 'Unknown'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown, Previously Positive', 'cancer_at_enc'] = 'Unknown'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown, Not Documented', 'cancer_at_enc'] = 'Unknown'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown, Not documented', 'cancer_at_enc'] = 'Unknown'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'No Cancer', 'cancer_at_enc'] = '1'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown', 'cancer_at_enc'] = '2'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Cancer', 'cancer_at_enc'] = '3'\n",
    "    mod_cancer_df['cancer_at_enc'] = mod_cancer_df['cancer_at_enc'].astype(int)\n",
    "    mod_cancer_df.drop_duplicates(['PATIENT_ID', 'HSP_ENC'])\n",
    "    \n",
    "    #Take only cancer status column with max value\n",
    "    drop_cancer_df = mod_cancer_df[['HSP_ENC', 'cancer_at_enc']]\n",
    "    drop_cancer_df = drop_cancer_df.groupby('HSP_ENC',group_keys=False).apply(lambda x: x.loc[x['cancer_at_enc']==x['cancer_at_enc'].max()])\n",
    "\n",
    "    #Merge with encounter df and drop dups\n",
    "    mergeRes = pd.merge(enc_df, drop_cancer_df, on='HSP_ENC', how='left')\n",
    "    mergeRes = mergeRes.drop_duplicates('HSP_ENC')\n",
    "\n",
    "    #Replace NaN in encounter df with 0 (Never had cancer)\n",
    "    mergeRes['cancer_at_enc'].fillna(0, inplace=True)\n",
    "    \n",
    "    #Renaming the cancer column\n",
    "    mergeRes.rename(columns={'cancer_at_enc': 'CANCER_RANK'}, inplace=True)\n",
    "    \n",
    "    mergeRes.reset_index(drop=True)\n",
    "    mergeRes.set_index(\"HSP_ENC\", inplace = True)\n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_registry(enc_df, reg_df):\n",
    "    reg_list = reg_df.REGISTRY_NAME.unique().tolist()\n",
    "    reg_df_copy = reg_df.copy()\n",
    "    reg_df_copy.reset_index(level=0, inplace=True)\n",
    "\n",
    "    tst_df = reg_df_copy[['HSP_ENC']].copy()\n",
    "    for item in reg_list:\n",
    "        tst_df[item] = False\n",
    "    tst_df = tst_df.drop_duplicates()\n",
    "\n",
    "\n",
    "    for index, row in reg_df_copy.iterrows():\n",
    "        enc_id = reg_df_copy.iloc[index, 0]\n",
    "        curr_reg = reg_df_copy.iloc[index, 2]\n",
    "        tst_df.loc[tst_df['HSP_ENC'] == enc_id, [curr_reg]] = True\n",
    "\n",
    "    #Merge with encounter df and drop dups\n",
    "    mergeRes = pd.merge(enc_df, tst_df, on='HSP_ENC', how='left')\n",
    "    mergeRes = mergeRes.drop_duplicates('HSP_ENC')\n",
    "    \n",
    "    #Replace NaN in encounter df with False, no record\n",
    "    for item in reg_list:\n",
    "        mergeRes[item].fillna(False, inplace=True)\n",
    "    \n",
    "    mergeRes.set_index(\"HSP_ENC\", inplace = True)\n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vitals(enc_df, data_path):\n",
    "    vital_data_path = os.path.join(data_path, 'vitals.csv')\n",
    "    vital_data_df = pd.read_csv(vital_data_path, encoding='ISO-8859-1')\n",
    "    vital_data_df = vital_data_df.drop('Unnamed: 0', 1)\n",
    "    \n",
    "    mergeRes = pd.merge(enc_df, vital_data_df, on='HSP_ENC', how='left')\n",
    "    mergeRes.set_index(\"HSP_ENC\", inplace = True)\n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_co_morbid(enc_df, data_path):\n",
    "    co_mobid_path = os.path.join(data_path, 'comorbitidity_score_sm2.csv')\n",
    "    co_mobid_df = pd.read_csv(co_mobid_path, encoding='ISO-8859-1')\n",
    "    \n",
    "    mergeRes = pd.merge(enc_df, co_mobid_df, on='HSP_ENC', how='left')\n",
    "    mergeRes.set_index(\"HSP_ENC\", inplace = True)\n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_labs(enc_df, data_path):\n",
    "    lab_data_path = os.path.join(data_path, 'cleaned_lab_data.csv')\n",
    "    lab_data_df = pd.read_csv(lab_data_path, encoding='ISO-8859-1')\n",
    "    \n",
    "    mergeRes = pd.merge(enc_df, lab_data_df, on='HSP_ENC', how='left')\n",
    "    mergeRes.set_index(\"HSP_ENC\", inplace = True)\n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_encounter_radiology(df_encounter, df_radiology, cutoff_OrderTime=12, cutoff_ED_Disp=12):\n",
    "    # generate a new df_CT dataframe\n",
    "    # 1. focus on 'CT ANGIOGRAM' only\n",
    "    # 2. order time within 12h\n",
    "    # 3. keep only the first order for the outliers (only one data point that has 2 orders)\n",
    "\n",
    "    df_CT = df_radiology[df_radiology['NAME'].apply(lambda x: x.startswith('CT AN'))]\n",
    "    df_CT = df_CT[df_CT['ORDER_TIME_DIFFSEC'] <= cutoff_OrderTime*3600]\n",
    "    df_CT = df_CT.drop_duplicates('HSP_ENC', keep='first')\n",
    "\n",
    "    # combine df_encounter and df_CT based on 'HSP_ENC' id\n",
    "    df_encounter = df_encounter[df_encounter['ED_DISP_TIME_DIFFSEC']<=cutoff_ED_Disp*3600]\n",
    "    df_enc_CT = pd.merge(df_encounter, df_CT, how='left', on='HSP_ENC')\n",
    "    df_enc_CT.set_index('HSP_ENC', inplace=True)\n",
    "    \n",
    "    return df_enc_CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_outcome(dfOutcome):\n",
    "    ## Outcome expansion   \n",
    "    \n",
    "    # Drop any outcomes after 48 hr\n",
    "    dfOutcome = dfOutcome[dfOutcome['ORDER_TIME_DIFFSEC']<48*60*60]\n",
    "    \n",
    "    # Create columns for each unique outcome\n",
    "    lsExpandedOutcomeCols = []\n",
    "    lsOutcomeColsToRetain = dfOutcome.columns[2:].tolist()\n",
    "    lsUniqueOutcomes = dfOutcome['name_gen'].value_counts().index.tolist()\n",
    "    for strOutcome in lsUniqueOutcomes:\n",
    "        lsExpandedOutcomeCols += [strCol + '_' + strOutcome for strCol in lsOutcomeColsToRetain]\n",
    "\n",
    "    dfExpandedOutcome = pd.DataFrame(columns=lsExpandedOutcomeCols+['PATIENT_ID'])\n",
    "    dfExpandedOutcome['HSP_ENC'] = dfOutcome['HSP_ENC'].value_counts().index\n",
    "    dfExpandedOutcome = dfExpandedOutcome.set_index('HSP_ENC')\n",
    "\n",
    "    for nEnc in dfOutcome['HSP_ENC'].value_counts().index:\n",
    "        for nIdx in dfOutcome[dfOutcome['HSP_ENC']==nEnc].index:\n",
    "            lsTempCols = [strCol + '_' + dfOutcome.at[nIdx, 'name_gen'] for strCol in lsOutcomeColsToRetain]\n",
    "            lsTempCols.append('PATIENT_ID')\n",
    "            dfExpandedOutcome.loc[nEnc, lsTempCols] = dfOutcome.loc[nIdx, lsOutcomeColsToRetain+['PATIENT_ID']].values\n",
    "\n",
    "    # Create boolean column for order time < 48 hrs for any outcome\n",
    "    lsOrderTimeCols = [strCol for strCol in dfExpandedOutcome.columns if 'ORDER_TIME' in strCol]\n",
    "\n",
    "    dfExpandedOutcome['b48hr'] = np.zeros(dfExpandedOutcome.shape[0])\n",
    "    for nEnc in dfExpandedOutcome.index:\n",
    "        for nVal in dfExpandedOutcome.loc[nEnc, lsOrderTimeCols].values:\n",
    "            if nVal < 172800:\n",
    "                dfExpandedOutcome.at[nEnc, 'b48hr'] = 1\n",
    "\n",
    "    # Column for minimum order time from all outcomes\n",
    "    dfExpandedOutcome['MinOrderTime'] = dfExpandedOutcome.loc[:, lsOrderTimeCols].min(axis=1)\n",
    "    dfExpandedOutcome = dfExpandedOutcome.sort_values('MinOrderTime')\n",
    "    \n",
    "    return dfExpandedOutcome\n",
    "\n",
    "\n",
    "def compile_echo(dfEcho):    \n",
    "    # Keep only 12 hr echos\n",
    "    dfEcho = dfEcho[dfEcho['ORDER_INST_DIFFSEC'] < 12*60*60]\n",
    "\n",
    "    # Add all narratives together\n",
    "    lsUniqueEchoEnc = dfEcho['HSP_ENC'].value_counts().index.tolist()\n",
    "\n",
    "    lsEchoCols = dfEcho.columns.tolist()\n",
    "    lsEchoCols.remove('new_line')\n",
    "    lsEchoCols.remove('NARRATIVE')\n",
    "    dfCompiledEcho = pd.DataFrame(columns=lsEchoCols)\n",
    "    dfCompiledEcho['HSP_ENC'] = lsUniqueEchoEnc\n",
    "    dfCompiledEcho = dfCompiledEcho.set_index('HSP_ENC')\n",
    "    lsEchoCols.remove('HSP_ENC')\n",
    "\n",
    "    lsCompiledNarratives = []\n",
    "    for nEnc in lsUniqueEchoEnc:\n",
    "        lsUniqueEchoOrderId = dfEcho[dfEcho['HSP_ENC']==nEnc]['ORDER_PROC_ID'].value_counts().index.tolist()\n",
    "        #if len(lsUniqueEchoOrderId)>1:\n",
    "            #print(nEnc)\n",
    "        nFirstEchoOrderId = lsUniqueEchoOrderId[0] # Keep first one only\n",
    "        \n",
    "        # Compile echo data\n",
    "        strCompiled = dfEcho[dfEcho['ORDER_PROC_ID']==nFirstEchoOrderId]['NARRATIVE'].str.cat(sep=' ')\n",
    "        dfCompiledEcho.loc[nEnc, lsEchoCols] = dfEcho[dfEcho['ORDER_PROC_ID']==nFirstEchoOrderId][lsEchoCols].iloc[0]\n",
    "        lsCompiledNarratives.append(strCompiled)\n",
    "    dfCompiledEcho['NARRATIVE_compiled'] = lsCompiledNarratives\n",
    "\n",
    "    # Keep only 12 hr echos\n",
    "    dfCompiledEcho = dfCompiledEcho[dfCompiledEcho['ORDER_INST_DIFFSEC'] < 12*60*60]\n",
    "    \n",
    "    return dfCompiledEcho\n",
    "\n",
    "def get_merge_dfs(dfOutcome, dfEcho, dfEncounter):\n",
    "    dfExpandedOutcome = expand_outcome(dfOutcome)\n",
    "    dfCompiledEcho = compile_echo(dfEcho)\n",
    "    dfEncounter = dfEncounter.set_index('HSP_ENC')\n",
    "    \n",
    "    dfMerged = dfEncounter.merge(dfExpandedOutcome, how='left', on='HSP_ENC')\n",
    "    dfMerged = dfMerged.merge(dfCompiledEcho, how='left', on='HSP_ENC')\n",
    "    \n",
    "    return dfMerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_labeled_echo(dfEchoLabeled):\n",
    "    # Changing mlid to mild\n",
    "    dfEchoLabeled['function'] = dfEchoLabeled['function'].replace('mlid', 'mild')\n",
    "    dfEchoLabeled['dilation'] = dfEchoLabeled['dilation'].replace('mlid', 'mild')\n",
    "    \n",
    "    # na to 0, mild to 1, moderate to 2, severe to 3\n",
    "    dictReplace = {'mild':1, 'moderate':2, 'severe':3}\n",
    "    dfEchoLabeled['function'] = dfEchoLabeled['function'].fillna(0)\n",
    "    dfEchoLabeled['function'] = dfEchoLabeled['function'].replace(dictReplace)\n",
    "\n",
    "    dfEchoLabeled['dilation'] = dfEchoLabeled['dilation'].fillna(0)\n",
    "    dfEchoLabeled['dilation'] = dfEchoLabeled['dilation'].replace(dictReplace)\n",
    "    \n",
    "    return dfEchoLabeled\n",
    "\n",
    "\n",
    "def merge_labeled_echo(dfMerged, dfEchoLabeled):\n",
    "    \"\"\"\n",
    "    Parse labeled echo data to keep matching enc, order_proc_id\n",
    "    If multiple rows per enc and order id, keep max bc this \n",
    "    represents different line of report\n",
    "    \"\"\"\n",
    "    srsIsNullNarrative = dfMerged['NARRATIVE_compiled'].isnull()\n",
    "    for nEnc in dfMerged.index:\n",
    "        nOrder = dfMerged.at[nEnc, 'ORDER_PROC_ID']\n",
    "        dfTemp = dfEchoLabeled[dfEchoLabeled['HSP_ENC']==nEnc]\n",
    "        dfTemp = dfTemp[dfTemp['ORDER_PROC_ID']==nOrder]\n",
    "        if dfTemp.shape[0] > 0:    \n",
    "            dfMerged.at[nEnc, 'echo_dilation'] = dfTemp['dilation'].max()\n",
    "            dfMerged.at[nEnc, 'echo_function'] = dfTemp['function'].max()\n",
    "        elif not srsIsNullNarrative[nEnc]:\n",
    "            dfMerged.at[nEnc, 'echo_dilation'] = 0\n",
    "            dfMerged.at[nEnc, 'echo_function'] = 0\n",
    "    \n",
    "    return dfMerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_echo(out_df, ech_df, enc_df, rad_df):\n",
    "    # read each dataset\n",
    "    mod_out_df = out_df.copy()\n",
    "    mod_out_df.reset_index(level=0, inplace=True)\n",
    "    mod_ech_df = ech_df.copy()\n",
    "    mod_ech_df.reset_index(level=0, inplace=True)\n",
    "    mod_enc_df = enc_df.copy()\n",
    "    mod_enc_df.reset_index(level=0, inplace=True)\n",
    "    mod_rad_df = rad_df.copy()\n",
    "    mod_rad_df.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    df_enc_echo_outcome = get_merge_dfs(mod_out_df, mod_ech_df, mod_enc_df)\n",
    "    df_enc_CT = merge_encounter_radiology(mod_enc_df, mod_rad_df)\n",
    "\n",
    "    # clean the dataset\n",
    "    df_cleaned = df_enc_echo_outcome.merge(df_enc_CT, how='left', on='HSP_ENC')\n",
    "\n",
    "    # raw column names\n",
    "    name_gen = []\n",
    "    for i in df_cleaned.columns.values:\n",
    "        if i.startswith('name_gen') or i.startswith('NARR'):\n",
    "            name_gen.append(i)\n",
    "    name_gen = sorted(name_gen) + ['b48hr']\n",
    "\n",
    "    # rename the column names\n",
    "    df_cleaned = df_cleaned[name_gen]\n",
    "    new_columns = ['CT', 'Echo', 'CPR', 'DEATH', 'INTUBATION', 'PPV', 'THROMBOLYSIS', 'THROMBOLYSIS_PROC', 'VASOPRESSORS', 'B48hr']\n",
    "    df_cleaned.columns = new_columns\n",
    "\n",
    "    # fill Nan\n",
    "    df_cleaned['CT'].fillna('No_CT', inplace=True)\n",
    "    df_cleaned['Echo'].fillna('No_Echo', inplace=True)\n",
    "    df_cleaned.fillna(0, inplace=True)\n",
    "\n",
    "    # convert to 1\n",
    "    map_dict = {'DEATH': 1, \n",
    "                'INTUBATION': 1,\n",
    "                'PPV': 1,\n",
    "                'THROMBOLYSIS': 1,\n",
    "                'THROMBOLYSIS_PROC': 1,\n",
    "                'VASOPRESSORS': 1,\n",
    "                0:0}\n",
    "    for col in ['DEATH', 'INTUBATION', 'PPV', 'THROMBOLYSIS', 'THROMBOLYSIS_PROC', 'VASOPRESSORS']:\n",
    "        df_cleaned[col] = df_cleaned[col].map(map_dict)\n",
    "        \n",
    "    \n",
    "    echo_tag_path = '/project/hackathon/hackers09/hack095/NOVEL-CLINICAL-PREDICTION-APPROACHES-TO-MANAGING-CARE-FOR-ACUTE-PULMONARY-EMBOLISM-PATIENTS/echo_tag.csv'\n",
    "    df_echo_label = pd.read_csv(echo_tag_path, encoding='ISO-8859-1')\n",
    "\n",
    "    dfEchoLabeled = preproc_labeled_echo(df_echo_label)\n",
    "    dfMerged = merge_labeled_echo(df_enc_echo_outcome, dfEchoLabeled)\n",
    "\n",
    "    #dfMerged.head()\n",
    "    df_new_features_echo_tags = dfMerged[['echo_dilation','echo_function']]\n",
    "    mergeRes = pd.merge(df_cleaned, df_new_features_echo_tags, on='HSP_ENC', how='left')\n",
    "        \n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(enc_df, data_path):\n",
    "    drop_path = os.path.join(data_path, \"final_enc_list.csv\")\n",
    "    drop_data = pd.read_csv(drop_path, encoding='ISO-8859-1')\n",
    "    \n",
    "    mergeRes = pd.merge(enc_df, drop_data, on='HSP_ENC')\n",
    "    mergeRes.set_index(\"HSP_ENC\", inplace = True)\n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_age_gender(master_df, enc_df):\n",
    "    age_gender_df = enc_df[['ENC_AGE', 'GENDER']].copy()\n",
    "    mergeRes = pd.merge(master_df, age_gender_df, on='HSP_ENC', how='left')\n",
    "        \n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = encounter_df\n",
    "output_data = merge_echo(outcome_df, echo_df, encounter_df, radiology_df)\n",
    "output_data = merge_cancer(output_data, cancer_df)\n",
    "output_data = merge_registry(output_data, registry_df)\n",
    "output_data = merge_vitals(output_data, data_path)\n",
    "output_data = merge_co_morbid(output_data, data_path)\n",
    "output_data = merge_labs(output_data, data_path)\n",
    "output_data = merge_age_gender(output_data, encounter_df)\n",
    "outcome = output_data.pop('B48hr')\n",
    "output_data['B48hr']=outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CT', 'Echo', 'CPR', 'DEATH', 'INTUBATION', 'PPV', 'THROMBOLYSIS',\n",
       "       'THROMBOLYSIS_PROC', 'VASOPRESSORS', 'echo_dilation', 'echo_function',\n",
       "       'CANCER_RANK', 'OBESITY REGISTRY', 'DIABETES REGISTRY', 'COPD REGISTRY',\n",
       "       'CONGESTIVE HEART FAILURE REGISTRY', 'GENERAL MALIGNANCY REGISTRY',\n",
       "       'CHRONIC LUNG REGISTRY', 'ASTHMA REGISTRY',\n",
       "       'CORONARY ARTERY DISEASE REGISTRY', 'CHRONIC HEART REGISTRY',\n",
       "       'SLEEP APNEA REGISTRY', 'LUNG CANCER REGISTRY',\n",
       "       'LIVER CIRRHOSIS REGISTRY', 'CRANIOTOMY REGISTRY',\n",
       "       'CHRONIC RENAL FAILURE REGISTRY', 'PULSE OXIMETRY_min',\n",
       "       'PULSE OXIMETRY_max', 'PULSE OXIMETRY_std', 'PULSE OXIMETRY_average',\n",
       "       'TEMPERATURE_min', 'TEMPERATURE_max', 'TEMPERATURE_std',\n",
       "       'TEMPERATURE_average', 'PULSE_min', 'PULSE_max', 'PULSE_std',\n",
       "       'PULSE_average', 'RESPIRATIONS_min', 'RESPIRATIONS_max',\n",
       "       'RESPIRATIONS_std', 'RESPIRATIONS_average',\n",
       "       'CPM F16 R AS OXYGEN AMOUNT_min', 'CPM F16 R AS OXYGEN AMOUNT_max',\n",
       "       'CPM F16 R AS OXYGEN AMOUNT_std', 'CPM F16 R AS OXYGEN AMOUNT_average',\n",
       "       'CPM F16 R INV OXYGEN CONCENTRATION (%)_min',\n",
       "       'CPM F16 R INV OXYGEN CONCENTRATION (%)_max',\n",
       "       'CPM F16 R INV OXYGEN CONCENTRATION (%)_std',\n",
       "       'CPM F16 R INV OXYGEN CONCENTRATION (%)_average',\n",
       "       'BLOOD PRESSURE SBP_min', 'BLOOD PRESSURE SBP_max',\n",
       "       'BLOOD PRESSURE SBP_std', 'BLOOD PRESSURE SBP_average',\n",
       "       'BLOOD PRESSURE DBP_min', 'BLOOD PRESSURE DBP_max',\n",
       "       'BLOOD PRESSURE DBP_std', 'BLOOD PRESSURE DBP_average', 'score',\n",
       "       'index', 'wscore', 'windex', 'N_TERMINAL_PROBNP', 'BNP_STATUS',\n",
       "       'TROPONIN_MAX', 'TROPONIN_STATUS', 'ENC_AGE', 'GENDER', 'B48hr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    #'CT',\n",
    "    #'Echo',\n",
    "    'CPR',\n",
    "    'DEATH',\n",
    "    'INTUBATION',\n",
    "    'PPV',\n",
    "    'THROMBOLYSIS',\n",
    "    'THROMBOLYSIS_PROC',\n",
    "    'VASOPRESSORS',\n",
    "    'echo_dilation',\n",
    "    'echo_function',\n",
    "    'CANCER_RANK',\n",
    "#     'OBESITY REGISTRY',\n",
    "#     'DIABETES REGISTRY',\n",
    "#     'COPD REGISTRY',\n",
    "#     'CONGESTIVE HEART FAILURE REGISTRY',\n",
    "#     #'GENERAL MALIGNANCY REGISTRY',\n",
    "#     'CHRONIC LUNG REGISTRY',\n",
    "#     #'ASTHMA REGISTRY',\n",
    "#     'CORONARY ARTERY DISEASE REGISTRY',\n",
    "#     #'CHRONIC HEART REGISTRY',\n",
    "#     'SLEEP APNEA REGISTRY',\n",
    "#     #'LUNG CANCER REGISTRY',\n",
    "#     'LIVER CIRRHOSIS REGISTRY',\n",
    "#     #'CRANIOTOMY REGISTRY',\n",
    "#     #'CHRONIC RENAL FAILURE REGISTRY',\n",
    "    'PULSE OXIMETRY_min',\n",
    "    #'PULSE OXIMETRY_max',\n",
    "    #'PULSE OXIMETRY_std',\n",
    "    #'PULSE OXIMETRY_average',\n",
    "    #'TEMPERATURE_min',\n",
    "    #'TEMPERATURE_max',\n",
    "    #'TEMPERATURE_std',\n",
    "    #'TEMPERATURE_average',\n",
    "    #'PULSE_min',\n",
    "    'PULSE_max',\n",
    "    #'PULSE_std',\n",
    "    #'PULSE_average',\n",
    "    #'RESPIRATIONS_min',\n",
    "    'RESPIRATIONS_max',\n",
    "    #'RESPIRATIONS_std',\n",
    "    #'RESPIRATIONS_average',\n",
    "    #'CPM F16 R AS OXYGEN AMOUNT_min',\n",
    "    #'CPM F16 R AS OXYGEN AMOUNT_max',\n",
    "    #'CPM F16 R AS OXYGEN AMOUNT_std',\n",
    "    #'CPM F16 R AS OXYGEN AMOUNT_average',\n",
    "    #'CPM F16 R INV OXYGEN CONCENTRATION (%)_min',\n",
    "    #'CPM F16 R INV OXYGEN CONCENTRATION (%)_max',\n",
    "    #'CPM F16 R INV OXYGEN CONCENTRATION (%)_std',\n",
    "    #'CPM F16 R INV OXYGEN CONCENTRATION (%)_average',\n",
    "    'BLOOD PRESSURE SBP_min',\n",
    "    #'BLOOD PRESSURE SBP_max',\n",
    "    #'BLOOD PRESSURE SBP_std',\n",
    "    #'BLOOD PRESSURE SBP_average',\n",
    "    'BLOOD PRESSURE DBP_min',\n",
    "    #'BLOOD PRESSURE DBP_max',\n",
    "    #'BLOOD PRESSURE DBP_std',\n",
    "    #'BLOOD PRESSURE DBP_average',\n",
    "    #'score',\n",
    "    #'index',\n",
    "    'wscore',\n",
    "    #'windex',\n",
    "    'BNP_STATUS',\n",
    "    'TROPONIN_MAX',\n",
    "    'TROPONIN_STATUS',\n",
    "    'ENC_AGE', 'GENDER',\n",
    "    'B48hr'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPR</th>\n",
       "      <th>DEATH</th>\n",
       "      <th>INTUBATION</th>\n",
       "      <th>PPV</th>\n",
       "      <th>THROMBOLYSIS</th>\n",
       "      <th>THROMBOLYSIS_PROC</th>\n",
       "      <th>VASOPRESSORS</th>\n",
       "      <th>echo_dilation</th>\n",
       "      <th>echo_function</th>\n",
       "      <th>CANCER_RANK</th>\n",
       "      <th>...</th>\n",
       "      <th>RESPIRATIONS_max</th>\n",
       "      <th>BLOOD PRESSURE SBP_min</th>\n",
       "      <th>BLOOD PRESSURE DBP_min</th>\n",
       "      <th>wscore</th>\n",
       "      <th>BNP_STATUS</th>\n",
       "      <th>TROPONIN_MAX</th>\n",
       "      <th>TROPONIN_STATUS</th>\n",
       "      <th>ENC_AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>B48hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSP_ENC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260755660</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192470437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258754156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306050512</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163297609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178796884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829587297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>MALE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802565292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829448073</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>MALE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816580713</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1642 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CPR  DEATH  INTUBATION  PPV  THROMBOLYSIS  THROMBOLYSIS_PROC  \\\n",
       "HSP_ENC                                                                   \n",
       "260755660    0      0           0    0             0                  0   \n",
       "192470437    0      0           0    0             0                  0   \n",
       "258754156    0      0           0    0             0                  0   \n",
       "306050512    0      0           0    0             1                  1   \n",
       "163297609    0      0           0    0             0                  0   \n",
       "...         ..    ...         ...  ...           ...                ...   \n",
       "178796884    0      0           0    0             0                  0   \n",
       "1829587297   0      0           1    0             0                  0   \n",
       "1802565292   0      0           0    0             0                  0   \n",
       "1829448073   0      0           0    0             0                  0   \n",
       "1816580713   0      0           0    0             0                  0   \n",
       "\n",
       "            VASOPRESSORS  echo_dilation  echo_function  CANCER_RANK  ...  \\\n",
       "HSP_ENC                                                              ...   \n",
       "260755660              0            0.0            0.0          2.0  ...   \n",
       "192470437              1            NaN            NaN          0.0  ...   \n",
       "258754156              0            NaN            NaN          0.0  ...   \n",
       "306050512              0            0.0            0.0          0.0  ...   \n",
       "163297609              0            NaN            NaN          3.0  ...   \n",
       "...                  ...            ...            ...          ...  ...   \n",
       "178796884              0            NaN            NaN          0.0  ...   \n",
       "1829587297             1            NaN            NaN          0.0  ...   \n",
       "1802565292             0            NaN            NaN          0.0  ...   \n",
       "1829448073             0            1.0            1.0          0.0  ...   \n",
       "1816580713             0            NaN            NaN          2.0  ...   \n",
       "\n",
       "            RESPIRATIONS_max  BLOOD PRESSURE SBP_min  BLOOD PRESSURE DBP_min  \\\n",
       "HSP_ENC                                                                        \n",
       "260755660               28.0                   106.0                    72.0   \n",
       "192470437               30.0                    96.0                    54.0   \n",
       "258754156               28.0                   119.0                    49.0   \n",
       "306050512               25.0                   112.0                    74.0   \n",
       "163297609               28.0                    92.0                    51.0   \n",
       "...                      ...                     ...                     ...   \n",
       "178796884               20.0                   134.0                    74.0   \n",
       "1829587297              39.0                   140.0                    69.0   \n",
       "1802565292              20.0                    98.0                    57.0   \n",
       "1829448073              20.0                   115.0                    54.0   \n",
       "1816580713              29.0                   134.0                    69.0   \n",
       "\n",
       "            wscore  BNP_STATUS  TROPONIN_MAX  TROPONIN_STATUS  ENC_AGE  \\\n",
       "HSP_ENC                                                                  \n",
       "260755660        6         NaN           NaN              NaN       60   \n",
       "192470437        5         1.0           NaN              NaN       74   \n",
       "258754156        3         NaN           NaN              NaN       96   \n",
       "306050512        1         1.0      0.004695              0.0       78   \n",
       "163297609        9         NaN           NaN              NaN       47   \n",
       "...            ...         ...           ...              ...      ...   \n",
       "178796884        8         NaN           NaN              NaN       57   \n",
       "1829587297       2         NaN           NaN              NaN       80   \n",
       "1802565292       0         NaN           NaN              NaN       31   \n",
       "1829448073       1         NaN           NaN              NaN       78   \n",
       "1816580713       2         NaN           NaN              NaN       79   \n",
       "\n",
       "            GENDER  B48hr  \n",
       "HSP_ENC                    \n",
       "260755660   FEMALE    0.0  \n",
       "192470437   FEMALE    1.0  \n",
       "258754156     MALE    0.0  \n",
       "306050512   FEMALE    1.0  \n",
       "163297609     MALE    0.0  \n",
       "...            ...    ...  \n",
       "178796884   FEMALE    0.0  \n",
       "1829587297    MALE    1.0  \n",
       "1802565292  FEMALE    0.0  \n",
       "1829448073    MALE    0.0  \n",
       "1816580713  FEMALE    0.0  \n",
       "\n",
       "[1642 rows x 22 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_data = output_data[cols_to_keep].copy()\n",
    "min_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FEMALE    862\n",
       "MALE      780\n",
       "Name: GENDER, dtype: int64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_data['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data['GENDER'] = min_data['GENDER'].replace({'MALE':1, 'FEMALE':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data['CPR'] = min_data['CPR'].replace('CPR', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data = min_data.loc[:, 'echo_dilation':'B48hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1642, 15)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>echo_dilation</th>\n",
       "      <th>echo_function</th>\n",
       "      <th>CANCER_RANK</th>\n",
       "      <th>PULSE OXIMETRY_min</th>\n",
       "      <th>PULSE_max</th>\n",
       "      <th>RESPIRATIONS_max</th>\n",
       "      <th>BLOOD PRESSURE SBP_min</th>\n",
       "      <th>BLOOD PRESSURE DBP_min</th>\n",
       "      <th>wscore</th>\n",
       "      <th>BNP_STATUS</th>\n",
       "      <th>TROPONIN_MAX</th>\n",
       "      <th>TROPONIN_STATUS</th>\n",
       "      <th>ENC_AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>B48hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HSP_ENC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260755660</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192470437</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258754156</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306050512</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163297609</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178796884</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829587297</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802565292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829448073</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816580713</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1642 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            echo_dilation  echo_function  CANCER_RANK  PULSE OXIMETRY_min  \\\n",
       "HSP_ENC                                                                     \n",
       "260755660             0.0            0.0          2.0                88.0   \n",
       "192470437             NaN            NaN          0.0                98.0   \n",
       "258754156             NaN            NaN          0.0                85.0   \n",
       "306050512             0.0            0.0          0.0                91.0   \n",
       "163297609             NaN            NaN          3.0                94.0   \n",
       "...                   ...            ...          ...                 ...   \n",
       "178796884             NaN            NaN          0.0                96.0   \n",
       "1829587297            NaN            NaN          0.0                94.0   \n",
       "1802565292            NaN            NaN          0.0                97.0   \n",
       "1829448073            1.0            1.0          0.0                87.0   \n",
       "1816580713            NaN            NaN          2.0                91.0   \n",
       "\n",
       "            PULSE_max  RESPIRATIONS_max  BLOOD PRESSURE SBP_min  \\\n",
       "HSP_ENC                                                           \n",
       "260755660       140.0              28.0                   106.0   \n",
       "192470437       127.0              30.0                    96.0   \n",
       "258754156        71.0              28.0                   119.0   \n",
       "306050512       145.0              25.0                   112.0   \n",
       "163297609       103.0              28.0                    92.0   \n",
       "...               ...               ...                     ...   \n",
       "178796884       114.0              20.0                   134.0   \n",
       "1829587297      132.0              39.0                   140.0   \n",
       "1802565292      123.0              20.0                    98.0   \n",
       "1829448073      108.0              20.0                   115.0   \n",
       "1816580713       90.0              29.0                   134.0   \n",
       "\n",
       "            BLOOD PRESSURE DBP_min  wscore  BNP_STATUS  TROPONIN_MAX  \\\n",
       "HSP_ENC                                                                \n",
       "260755660                     72.0       6         NaN           NaN   \n",
       "192470437                     54.0       5         1.0           NaN   \n",
       "258754156                     49.0       3         NaN           NaN   \n",
       "306050512                     74.0       1         1.0      0.004695   \n",
       "163297609                     51.0       9         NaN           NaN   \n",
       "...                            ...     ...         ...           ...   \n",
       "178796884                     74.0       8         NaN           NaN   \n",
       "1829587297                    69.0       2         NaN           NaN   \n",
       "1802565292                    57.0       0         NaN           NaN   \n",
       "1829448073                    54.0       1         NaN           NaN   \n",
       "1816580713                    69.0       2         NaN           NaN   \n",
       "\n",
       "            TROPONIN_STATUS  ENC_AGE  GENDER  B48hr  \n",
       "HSP_ENC                                              \n",
       "260755660               NaN       60       0    0.0  \n",
       "192470437               NaN       74       0    1.0  \n",
       "258754156               NaN       96       1    0.0  \n",
       "306050512               0.0       78       0    1.0  \n",
       "163297609               NaN       47       1    0.0  \n",
       "...                     ...      ...     ...    ...  \n",
       "178796884               NaN       57       0    0.0  \n",
       "1829587297              NaN       80       1    1.0  \n",
       "1802565292              NaN       31       0    0.0  \n",
       "1829448073              NaN       78       1    0.0  \n",
       "1816580713              NaN       79       0    0.0  \n",
       "\n",
       "[1642 rows x 15 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSeed = 42\n",
    "np.random.seed(nSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictSplitIndices = {}\n",
    "\n",
    "nOuterFolds = 3\n",
    "nInnerFolds = 3\n",
    "\n",
    "nSamples = min_data.shape[0]\n",
    "\n",
    "objOuterStrat = StratifiedKFold(n_splits=nOuterFolds, shuffle=True,\n",
    "                                random_state=nSeed)\n",
    "objInnerStrat = StratifiedKFold(n_splits=nInnerFolds, shuffle=True,\n",
    "                                    random_state=nSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsOuterSplits = list(objOuterStrat.split(np.zeros(nSamples), min_data['B48hr']))\n",
    "lsTupInnerSplits = []\n",
    "for nOuterIdx, tupOuterSplits in enumerate(lsOuterSplits):\n",
    "    arrOuterTrain = tupOuterSplits[0]\n",
    "    arrOuterTest = tupOuterSplits[1]\n",
    "    \n",
    "    dictSplitIndices['outer_train_{}'.format(nOuterIdx)] = arrOuterTrain\n",
    "    dictSplitIndices['outer_test_{}'.format(nOuterIdx)] = arrOuterTest\n",
    "    \n",
    "    nInnerTrainSamples = len(arrOuterTrain)\n",
    "    lsInnerSplits = list(objInnerStrat.split(np.zeros(nInnerTrainSamples),\n",
    "                                             min_data['B48hr'].iloc[arrOuterTrain]))\n",
    "    for nInnerIdx, tupInnerSplits in enumerate(lsInnerSplits):\n",
    "        arrInnerTrain = tupInnerSplits[0]\n",
    "        arrInnerTest = tupInnerSplits[1]\n",
    "        \n",
    "        arrInnerTrain = arrOuterTrain[arrInnerTrain]\n",
    "        arrInnerTest = arrOuterTrain[arrInnerTest]\n",
    "        dictSplitIndices['outer_{}_inner_train_{}'.format(nOuterIdx, nInnerIdx)] = arrInnerTrain\n",
    "        dictSplitIndices['outer_{}_inner_test_{}'.format(nOuterIdx, nInnerIdx)] = arrInnerTest\n",
    "        \n",
    "        lsTupInnerSplits.append((arrInnerTrain, arrInnerTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conducting random search on min_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "nModelConfigs = 4\n",
    "dfModelSearch = pd.DataFrame(columns=['estimator', 'param_distributions', \n",
    "                                      'best_inner_models', 'cv_results',\n",
    "                                      'test_results', 'test_predictions'],\n",
    "                             index=range(nModelConfigs))\n",
    "dfModelSearch['test_predictions'] = dfModelSearch['test_predictions'].astype('object')\n",
    "dfModelSearch['test_results'] = dfModelSearch['test_results'].astype('object')\n",
    "dfModelSearch['estimator'] = [SVC(), DecisionTreeClassifier(), \n",
    "                              GradientBoostingClassifier(), MLPClassifier()]\n",
    "dfModelSearch['param_distributions'] = [{'C': np.arange(0.1, 1, 0.1),\n",
    "                                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                                         'degree': np.arange(3, 100, 3),\n",
    "                                         'gamma': ['scale']},\n",
    "                                        {'criterion': ['gini', 'entropy'],\n",
    "                                         'splitter': ['best', 'random'],\n",
    "                                         'max_depth': [None, 100, 500, 1000],\n",
    "                                         'max_leaf_nodes': [None, 100, 500, 1000],\n",
    "                                         'min_samples_split': np.arange(0.1, 1, 0.1),\n",
    "                                         'max_features':['auto', 'sqrt', 'log2', None]},\n",
    "                                        {'loss':['deviance', 'exponential'],\n",
    "                                         'learning_rate':np.arange(0.1, 1, 0.1),\n",
    "                                         'n_estimators': np.arange(100, 5000, 100),\n",
    "                                         'max_depth': [None, 100, 500, 1000]},\n",
    "                                        {'hidden_layer_sizes': [(100,),\n",
    "                                                                (100,)*5,\n",
    "                                                                (100,)*10,\n",
    "                                                                (100,)*20],\n",
    "                                         'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                                         'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                                         'learning_rate': ['constant', 'invscaling', 'adaptive']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ls_best_model_params(dictCvResults, nOuterFolds, lsSummaryMetrics):\n",
    "    dfCvResults = pd.DataFrame(dictCvResults)\n",
    "    lsBestParams = []\n",
    "    for strCol in lsSummaryMetrics:\n",
    "        nIdxMax = dfCvResults[strCol].idxmax()\n",
    "        lsBestParams.append(dfCvResults.at[nIdxMax, 'params'])\n",
    "        \n",
    "    return lsBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_summary_measures_dictCv(dictCvResults, nOuterFolds, nInnerFolds):\n",
    "    dfCvResults = pd.DataFrame(dictCvResults)\n",
    "    for nOuter in range(nOuterFolds):\n",
    "        lsKeys = ['split{}_test_score'.format(nInner) for nInner in range(nOuter*nInnerFolds, nOuter*nInnerFolds + nInnerFolds)]\n",
    "        # Compute bottom 25th percentile\n",
    "        dfCvResults['outer{}_test_score_summary'.format(nOuter)] = dfCvResults[lsKeys].mean(axis=1) - dfCvResults[lsKeys].std(axis=1)*1.645 \n",
    "\n",
    "    return dfCvResults.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(nConfig, dfModelSearch, dfData, lsFeatures, strTarget):\n",
    "    objRandomSearch = RandomizedSearchCV(dfModelSearch.at[nConfig, 'estimator'],\n",
    "                                         dfModelSearch.at[nConfig, 'param_distributions'],\n",
    "                                         n_iter=50,\n",
    "                                         scoring='roc_auc',\n",
    "                                         random_state=nSeed,\n",
    "                                         return_train_score=True,\n",
    "                                         n_jobs=-1,\n",
    "                                         cv=lsTupInnerSplits)\n",
    "    \n",
    "    objScaler = StandardScaler()\n",
    "    objImpute = SimpleImputer(strategy='median')\n",
    "\n",
    "    lsSteps = [('std_scaler', objScaler),\n",
    "               ('simple_imputer', objImpute),\n",
    "               ('random_search', objRandomSearch)]\n",
    "\n",
    "    objPipeline = Pipeline(lsSteps)\n",
    "    \n",
    "    objPipeline.fit(dfData[lsFeatures], dfData[strTarget])\n",
    "    \n",
    "    dictCvResults = objPipeline.named_steps['random_search'].cv_results_\n",
    "    dictCvResults = add_summary_measures_dictCv(dictCvResults, nOuterFolds, nInnerFolds)\n",
    "    dfModelSearch.at[nConfig, 'cv_results'] = dictCvResults\n",
    "\n",
    "    lsSummaryMetrics = ['outer{}_test_score_summary'.format(nOuter) for nOuter in range(nOuterFolds)]\n",
    "    dfModelSearch.at[nConfig, 'best_inner_models'] = get_ls_best_model_params(dictCvResults, \n",
    "                                                                              nOuterFolds,\n",
    "                                                                              lsSummaryMetrics)\n",
    "    \n",
    "    dfModelSearch.at[nConfig, 'test_results'] = []\n",
    "    dfModelSearch.at[nConfig, 'test_predictions'] = []\n",
    "    for dictParams in dfModelSearch.at[nConfig, 'best_inner_models']:\n",
    "        objBestModel = dfModelSearch.at[nConfig, 'estimator']\n",
    "        objBestModel.set_params(**dictParams)\n",
    "        objTestPipeline = Pipeline([('std_scaler', objScaler),\n",
    "                            ('simple_imputer', objImpute),\n",
    "                            ('best_model', objBestModel)])\n",
    "        arrTrain = dictSplitIndices['outer_train_{}'.format(nOuterFold)]\n",
    "        arrTest = dictSplitIndices['outer_test_{}'.format(nOuterFold)]\n",
    "\n",
    "        arrTrainX = dfData[lsFeatures].iloc[arrTrain].values\n",
    "        arrTrainY = dfData[strTarget].iloc[arrTrain].values\n",
    "\n",
    "        arrTestX = dfData[lsFeatures].iloc[arrTest]\n",
    "        arrTestY = dfData[strTarget].iloc[arrTest]\n",
    "        objTestPipeline.fit(arrTrainX, \n",
    "                        arrTrainY)\n",
    "        dfModelSearch.at[nConfig, 'test_results'].append(objTestPipeline.score(arrTestX, arrTestY))\n",
    "        dfModelSearch.at[nConfig, 'test_predictions'].append(objTestPipeline.predict(arrTestX))\n",
    "        print(objTestPipeline.score(arrTestX,\n",
    "                                arrTestY))    \n",
    "    return dfModelSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dfModelSearch.index:\n",
    "    dfModelSearch = run_random_search(0, dfModelSearch, min_data, min_data.columns[:-1], min_data.columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bestModel.p\", \"wb\") as objFile:\n",
    "    pickle.dump(objTestPipeline, objFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras and DNN search and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
