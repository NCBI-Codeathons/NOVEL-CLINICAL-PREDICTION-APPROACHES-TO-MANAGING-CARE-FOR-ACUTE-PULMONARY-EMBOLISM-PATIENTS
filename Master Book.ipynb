{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths to files\n",
    "data_path = 'Q:/hackers09/shared/data/'\n",
    "cancer_path = os.path.join(data_path, 'df_cancer.csv')\n",
    "echo_path = os.path.join(data_path, 'df_echo.csv')\n",
    "encounter_path = os.path.join(data_path, 'df_encounter.csv')\n",
    "labs_path = os.path.join(data_path, 'df_labs.csv')\n",
    "outcome_path = os.path.join(data_path, 'df_outcome.csv')\n",
    "problist_path = os.path.join(data_path, 'df_problist.csv')\n",
    "radiology_path = os.path.join(data_path, 'df_radiology.csv')\n",
    "registry_path = os.path.join(data_path, 'df_registry.csv')\n",
    "vitals_path = os.path.join(data_path, 'df_vitals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in dataframes\n",
    "cancer_df = pd.read_csv(cancer_path, encoding='ISO-8859-1')\n",
    "cancer_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "echo_df = pd.read_csv(echo_path, encoding='ISO-8859-1')\n",
    "echo_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "encounter_df = pd.read_csv(encounter_path, encoding='ISO-8859-1')\n",
    "encounter_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "labs_df = pd.read_csv(labs_path, encoding='ISO-8859-1')\n",
    "labs_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "outcome_df = pd.read_csv(outcome_path, encoding='ISO-8859-1')\n",
    "outcome_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "problist_df = pd.read_csv(problist_path, encoding='ISO-8859-1')\n",
    "problist_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "radiology_df = pd.read_csv(radiology_path, encoding='ISO-8859-1')\n",
    "radiology_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "registry_df = pd.read_csv(registry_path, encoding='ISO-8859-1')\n",
    "registry_df.set_index(\"HSP_ENC\", inplace = True)\n",
    "vitals_df = pd.read_csv(vitals_path, encoding='ISO-8859-1')\n",
    "vitals_df.set_index(\"HSP_ENC\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "## Define functions to merge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to merge cancer data\n",
    "def merge_cancer(enc_df, cnc_df):\n",
    "    #Make modifications to cancer df\n",
    "    mod_cancer_df = cnc_df.copy()\n",
    "    mod_cancer_df.reset_index(level=0, inplace=True)\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown, Missing Remission Date', 'cancer_at_enc'] = 'Unknown'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown, Previously Positive', 'cancer_at_enc'] = 'Unknown'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown, Not Documented', 'cancer_at_enc'] = 'Unknown'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown, Not documented', 'cancer_at_enc'] = 'Unknown'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'No Cancer', 'cancer_at_enc'] = '1'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Unknown', 'cancer_at_enc'] = '2'\n",
    "    mod_cancer_df.loc[mod_cancer_df.cancer_at_enc == 'Cancer', 'cancer_at_enc'] = '3'\n",
    "    mod_cancer_df['cancer_at_enc'] = mod_cancer_df['cancer_at_enc'].astype(int)\n",
    "    mod_cancer_df.drop_duplicates(['PATIENT_ID', 'HSP_ENC'])\n",
    "    \n",
    "    #Take only cancer status column with max value\n",
    "    drop_cancer_df = mod_cancer_df[['HSP_ENC', 'cancer_at_enc']]\n",
    "    drop_cancer_df = drop_cancer_df.groupby('HSP_ENC',group_keys=False).apply(lambda x: x.loc[x['cancer_at_enc']==x['cancer_at_enc'].max()])\n",
    "\n",
    "    #Merge with encounter df and drop dups\n",
    "    mergeRes = pd.merge(enc_df, drop_cancer_df, on='HSP_ENC', how='left')\n",
    "    mergeRes = mergeRes.drop_duplicates('HSP_ENC')\n",
    "\n",
    "    #Replace NaN in encounter df with 0 (Never had cancer)\n",
    "    mergeRes['cancer_at_enc'].fillna(0, inplace=True)\n",
    "    \n",
    "    #Renaming the cancer column\n",
    "    mergeRes.rename(columns={'cancer_at_enc': 'CANCER_RANK'}, inplace=True)\n",
    "    \n",
    "    mergeRes.reset_index(drop=True)\n",
    "    mergeRes.set_index(\"HSP_ENC\", inplace = True)\n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_registry(enc_df, reg_df):\n",
    "    reg_list = reg_df.REGISTRY_NAME.unique().tolist()\n",
    "    reg_df_copy = reg_df.copy()\n",
    "    reg_df_copy.reset_index(level=0, inplace=True)\n",
    "\n",
    "    tst_df = reg_df_copy[['HSP_ENC']].copy()\n",
    "    for item in reg_list:\n",
    "        tst_df[item] = False\n",
    "    tst_df = tst_df.drop_duplicates()\n",
    "\n",
    "\n",
    "    for index, row in reg_df_copy.iterrows():\n",
    "        enc_id = reg_df_copy.iloc[index, 0]\n",
    "        curr_reg = reg_df_copy.iloc[index, 2]\n",
    "        tst_df.loc[tst_df['HSP_ENC'] == enc_id, [curr_reg]] = True\n",
    "\n",
    "    #Merge with encounter df and drop dups\n",
    "    mergeRes = pd.merge(enc_df, tst_df, on='HSP_ENC', how='left')\n",
    "    mergeRes = mergeRes.drop_duplicates('HSP_ENC')\n",
    "    \n",
    "    #Replace NaN in encounter df with False, no record\n",
    "    for item in reg_list:\n",
    "        mergeRes[item].fillna(False, inplace=True)\n",
    "    \n",
    "    mergeRes.set_index(\"HSP_ENC\", inplace = True)\n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vitals(enc_df, data_path):\n",
    "    vital_data_path = os.path.join(data_path, 'vitals.csv')\n",
    "    vital_data_df = pd.read_csv(vital_data_path, encoding='ISO-8859-1')\n",
    "    vital_data_df = vital_data_df.drop('Unnamed: 0', 1)\n",
    "    \n",
    "    mergeRes = pd.merge(enc_df, vital_data_df, on='HSP_ENC', how='left')\n",
    "    mergeRes.set_index(\"HSP_ENC\", inplace = True)\n",
    "    return mergeRes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radiology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_encounter_radiology(df_encounter, df_radiology, cutoff_OrderTime=12, cutoff_ED_Disp=12):\n",
    "    # generate a new df_CT dataframe\n",
    "    # 1. focus on 'CT ANGIOGRAM' only\n",
    "    # 2. order time within 12h\n",
    "    # 3. keep only the first order for the outliers (only one data point that has 2 orders)\n",
    "\n",
    "    df_CT = df_radiology[df_radiology['NAME'].apply(lambda x: x.startswith('CT AN'))]\n",
    "    df_CT = df_CT[df_CT['ORDER_TIME_DIFFSEC'] <= cutoff_OrderTime*3600]\n",
    "    df_CT = df_CT.drop_duplicates('HSP_ENC', keep='first')\n",
    "\n",
    "    # combine df_encounter and df_CT based on 'HSP_ENC' id\n",
    "    df_encounter = df_encounter[df_encounter['ED_DISP_TIME_DIFFSEC']<=cutoff_ED_Disp*3600]\n",
    "    df_enc_CT = pd.merge(df_encounter, df_CT, how='left', on='HSP_ENC')\n",
    "    df_enc_CT.set_index('HSP_ENC', inplace=True)\n",
    "    \n",
    "    return df_enc_CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_outcome(dfOutcome):\n",
    "    ## Outcome expansion   \n",
    "    \n",
    "    # Drop any outcomes after 48 hr\n",
    "    dfOutcome = dfOutcome[dfOutcome['ORDER_TIME_DIFFSEC']<48*60*60]\n",
    "    \n",
    "    # Create columns for each unique outcome\n",
    "    lsExpandedOutcomeCols = []\n",
    "    lsOutcomeColsToRetain = dfOutcome.columns[2:].tolist()\n",
    "    lsUniqueOutcomes = dfOutcome['name_gen'].value_counts().index.tolist()\n",
    "    for strOutcome in lsUniqueOutcomes:\n",
    "        lsExpandedOutcomeCols += [strCol + '_' + strOutcome for strCol in lsOutcomeColsToRetain]\n",
    "\n",
    "    dfExpandedOutcome = pd.DataFrame(columns=lsExpandedOutcomeCols+['PATIENT_ID'])\n",
    "    dfExpandedOutcome['HSP_ENC'] = dfOutcome['HSP_ENC'].value_counts().index\n",
    "    dfExpandedOutcome = dfExpandedOutcome.set_index('HSP_ENC')\n",
    "\n",
    "    for nEnc in dfOutcome['HSP_ENC'].value_counts().index:\n",
    "        for nIdx in dfOutcome[dfOutcome['HSP_ENC']==nEnc].index:\n",
    "            lsTempCols = [strCol + '_' + dfOutcome.at[nIdx, 'name_gen'] for strCol in lsOutcomeColsToRetain]\n",
    "            lsTempCols.append('PATIENT_ID')\n",
    "            dfExpandedOutcome.loc[nEnc, lsTempCols] = dfOutcome.loc[nIdx, lsOutcomeColsToRetain+['PATIENT_ID']].values\n",
    "\n",
    "    # Create boolean column for order time < 48 hrs for any outcome\n",
    "    lsOrderTimeCols = [strCol for strCol in dfExpandedOutcome.columns if 'ORDER_TIME' in strCol]\n",
    "\n",
    "    dfExpandedOutcome['b48hr'] = np.zeros(dfExpandedOutcome.shape[0])\n",
    "    for nEnc in dfExpandedOutcome.index:\n",
    "        for nVal in dfExpandedOutcome.loc[nEnc, lsOrderTimeCols].values:\n",
    "            if nVal < 172800:\n",
    "                dfExpandedOutcome.at[nEnc, 'b48hr'] = 1\n",
    "\n",
    "    # Column for minimum order time from all outcomes\n",
    "    dfExpandedOutcome['MinOrderTime'] = dfExpandedOutcome.loc[:, lsOrderTimeCols].min(axis=1)\n",
    "    dfExpandedOutcome = dfExpandedOutcome.sort_values('MinOrderTime')\n",
    "    \n",
    "    return dfExpandedOutcome\n",
    "\n",
    "\n",
    "def compile_echo(dfEcho):    \n",
    "    # Keep only 12 hr echos\n",
    "    dfEcho = dfEcho[dfEcho['ORDER_INST_DIFFSEC'] < 12*60*60]\n",
    "\n",
    "    # Add all narratives together\n",
    "    lsUniqueEchoEnc = dfEcho['HSP_ENC'].value_counts().index.tolist()\n",
    "\n",
    "    lsEchoCols = dfEcho.columns.tolist()\n",
    "    lsEchoCols.remove('new_line')\n",
    "    lsEchoCols.remove('NARRATIVE')\n",
    "    dfCompiledEcho = pd.DataFrame(columns=lsEchoCols)\n",
    "    dfCompiledEcho['HSP_ENC'] = lsUniqueEchoEnc\n",
    "    dfCompiledEcho = dfCompiledEcho.set_index('HSP_ENC')\n",
    "    lsEchoCols.remove('HSP_ENC')\n",
    "\n",
    "    lsCompiledNarratives = []\n",
    "    for nEnc in lsUniqueEchoEnc:\n",
    "        lsUniqueEchoOrderId = dfEcho[dfEcho['HSP_ENC']==nEnc]['ORDER_PROC_ID'].value_counts().index.tolist()\n",
    "        #if len(lsUniqueEchoOrderId)>1:\n",
    "            #print(nEnc)\n",
    "        nFirstEchoOrderId = lsUniqueEchoOrderId[0] # Keep first one only\n",
    "        \n",
    "        # Compile echo data\n",
    "        strCompiled = dfEcho[dfEcho['ORDER_PROC_ID']==nFirstEchoOrderId]['NARRATIVE'].str.cat(sep=' ')\n",
    "        dfCompiledEcho.loc[nEnc, lsEchoCols] = dfEcho[dfEcho['ORDER_PROC_ID']==nFirstEchoOrderId][lsEchoCols].iloc[0]\n",
    "        lsCompiledNarratives.append(strCompiled)\n",
    "    dfCompiledEcho['NARRATIVE_compiled'] = lsCompiledNarratives\n",
    "\n",
    "    # Keep only 12 hr echos\n",
    "    dfCompiledEcho = dfCompiledEcho[dfCompiledEcho['ORDER_INST_DIFFSEC'] < 12*60*60]\n",
    "    \n",
    "    return dfCompiledEcho\n",
    "\n",
    "def get_merge_dfs(dfOutcome, dfEcho, dfEncounter):\n",
    "    dfExpandedOutcome = expand_outcome(dfOutcome)\n",
    "    dfCompiledEcho = compile_echo(dfEcho)\n",
    "    dfEncounter = dfEncounter.set_index('HSP_ENC')\n",
    "    \n",
    "    dfMerged = dfEncounter.merge(dfExpandedOutcome, how='left', on='HSP_ENC')\n",
    "    dfMerged = dfMerged.merge(dfCompiledEcho, how='left', on='HSP_ENC')\n",
    "    \n",
    "    return dfMerged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks like this is working now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_echo(out_df, ech_df, enc_df, rad_df):\n",
    "    # read each dataset\n",
    "    mod_out_df = out_df.copy()\n",
    "    mod_out_df.reset_index(level=0, inplace=True)\n",
    "    mod_ech_df = ech_df.copy()\n",
    "    mod_ech_df.reset_index(level=0, inplace=True)\n",
    "    mod_enc_df = enc_df.copy()\n",
    "    mod_enc_df.reset_index(level=0, inplace=True)\n",
    "    mod_rad_df = rad_df.copy()\n",
    "    mod_rad_df.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    df_enc_echo_outcome = get_merge_dfs(mod_out_df, mod_ech_df, mod_enc_df)\n",
    "    df_enc_CT = merge_encounter_radiology(mod_enc_df, mod_rad_df)\n",
    "\n",
    "    # clean the dataset\n",
    "    df_cleaned = df_enc_echo_outcome.merge(df_enc_CT, how='left', on='HSP_ENC')\n",
    "\n",
    "    # raw column names\n",
    "    name_gen = []\n",
    "    for i in df_cleaned.columns.values:\n",
    "        if i.startswith('name_gen') or i.startswith('NARR'):\n",
    "            name_gen.append(i)\n",
    "    name_gen = sorted(name_gen) + ['b48hr']\n",
    "\n",
    "    # rename the column names\n",
    "    df_cleaned = df_cleaned[name_gen]\n",
    "    new_columns = ['CT', 'Echo', 'CPR', 'DEATH', 'INTUBATION', 'PPV', 'THROMBOLYSIS', 'THROMBOLYSIS_PROC', 'VASOPRESSORS', 'B48hr']\n",
    "    df_cleaned.columns = new_columns\n",
    "\n",
    "    # fill Nan\n",
    "    df_cleaned['CT'].fillna('No_CT', inplace=True)\n",
    "    df_cleaned['Echo'].fillna('No_Echo', inplace=True)\n",
    "    df_cleaned.fillna(0, inplace=True)\n",
    "\n",
    "    # convert to 1\n",
    "    map_dict = {'DEATH': 1, \n",
    "                'INTUBATION': 1,\n",
    "                'PPV': 1,\n",
    "                'THROMBOLYSIS': 1,\n",
    "                'THROMBOLYSIS_PROC': 1,\n",
    "                'VASOPRESSORS': 1,\n",
    "                0:0}\n",
    "    for col in ['DEATH', 'INTUBATION', 'PPV', 'THROMBOLYSIS', 'THROMBOLYSIS_PROC', 'VASOPRESSORS']:\n",
    "        df_cleaned[col] = df_cleaned[col].map(map_dict)\n",
    "        \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "## Start calling merge functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "encounter_df = merge_cancer(encounter_df, cancer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_df = merge_registry(encounter_df, registry_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_df = merge_vitals(encounter_df, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_df = merge_echo(outcome_df, echo_df, encounter_df, radiology_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encounter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "## Preprocess / Normalize the merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:, -1]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "##  Define params and run gridsearch to find best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, None],\n",
    "    'min_samples_split': [2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-f9727816d638>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(RandomForestClassifier(), params, cv=5, scoring = 'roc_auc')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "## Testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
